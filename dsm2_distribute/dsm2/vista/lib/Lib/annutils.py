__version__='0.7'
__doc__ = '''

A set of utilities to build pattern sets using regular time series data
sets and a given set of parameters. These are intended to replace the awk
scripts that read from text files and generated those pattern sets

Extraction of target and simulated values can be done either using the
simulate function generated by compiling the java file generated from snns2java.awk
or by using the extractres function directly on the .res
file from SNNS.

No replacement stratgies are attempted here. There are plenty of tools
outside this module designed for this.

'''
__future_tasks__='''
version 0.5
X1. Need to convert snns2java.awk to a function in this script
X2. Compiling and generation of UnitType.jav can be done in this script
version 0.6
3. gcalc for "G" model calculation needs to be verified!
version 0.7
Checked for accuracy with old awk scripts.
'''
__author__='Nicky Sandhu'
import vutils,time,string,jarray
from vista.set import Constants,MultiIterator,DataReference, NaNFilter
from java.io import BufferedOutputStream,FileOutputStream,PrintStream
def buildinput(rts, ndays, navgs, lenavgs):
    '''
    buildinput(rts):
    This builds a set of time series each of which is a present or past value of
    the given time series. Some of the values may be obtained by period averaging
    over a week.
    '''
    orts = []
    nrts = ndays+navgs
    # always append rts
    orts.append(rts)
    # append needed previous daily values
    for i in range(ndays): orts.append(rts >> (i+1))
    # adjust by 1 as present point always in average
    avgrts = vutils.mov_avg(rts,lenavgs-1,0)
    # append averaged values
    for i in range(ndays,navgs+ndays):
	shift = (i-ndays)*lenavgs+ndays+1
	orts.append(avgrts >> shift)
    return orts
def dump_patterns(inputs,outputs,outfile,calibration_percentage=0.75,skip = 365,append=0,
		  fast_write=0):
    '''
    dump_patterns(inputs,outputs,outfile,calibration_percentage=0.75,append=0):
    dumps the patterns to the given outfile.
    outfile.cal which contains calibration% of the points
    outfile.ver which contains validation% = 100 - calibration% of the points
    append=1 appends to the previous .cal and .ver files if they exist
    '''
    bufsize=15000
    #fast_write=0
    prev_no_patterns = [0,0]
    if append:
	cfh = open(outfile+'.cal','r+',bufsize)
	vfh = open(outfile+'.ver','r+',bufsize)
	id = 0
	for fh in [cfh,vfh]:
	    while 1:
		line = string.strip(fh.readline())
		if string.find(line,'No. of patterns') >=0:
		    prev_no_patterns[id] = int(line[string.find(line,':')+1:])
		if string.find(line,'Input pattern')>=0: break
	    fh.seek(0)
	    id = id + 1
    else:
	if fast_write:
	    cfh = PrintStream(BufferedOutputStream(FileOutputStream(outfile+'.cal')))
	    vfh = PrintStream(BufferedOutputStream(FileOutputStream(outfile+'.ver')))
	else:
	    cfh = open(outfile+'.cal','w',bufsize)
	    vfh = open(outfile+'.ver','w',bufsize)
    #
    #if append:
    #	print 'Prev # of patterns = %s'%prev_no_patterns
    npatterns = len(inputs[0]) - skip # skip beginning
    #print 'Time Window of inputs[0] %s'%str(inputs[0].getTimeWindow())
    #print npatterns,len(inputs[0]),skip
    ncalibs = calibration_percentage*npatterns
    ninputs = len(inputs)
    noutputs = len(outputs)
    #print 'Ncalibs: %d & Nverse: %d'%(ncalibs,npatterns-ncalibs)
    if append or not fast_write:
	cfh.write('''SNNS pattern definition file V3.2
generated at date                : %s
No. of patterns                  : %d
No. of input units               : %d
No. of output units              : %d

'''%(time.ctime(time.time()),ncalibs+prev_no_patterns[0],ninputs,noutputs))
	vfh.write('''SNNS pattern definition file V3.2
generated at date                : %s
No. of patterns                  : %d
No. of input units               : %d
No. of output units              : %d

'''%(time.ctime(time.time()),npatterns-ncalibs+prev_no_patterns[1],ninputs,noutputs))
    else:
	cfh.print('''SNNS pattern definition file V3.2
generated at date                : %s
No. of patterns                  : %d
No. of input units               : %d
No. of output units              : %d

'''%(time.ctime(time.time()),ncalibs+prev_no_patterns[0],ninputs,noutputs))
	vfh.print('''SNNS pattern definition file V3.2
generated at date                : %s
No. of patterns                  : %d
No. of input units               : %d
No. of output units              : %d

'''%(time.ctime(time.time()),npatterns-ncalibs+prev_no_patterns[1],ninputs,noutputs))
    #
    #goto end of file
    if append:
	for fh in [cfh,vfh]:
	    if fast_write:
		fh.close()
	    else:
		fh.seek(0,2)
	if fast_write:
	    cfh = PrintStream(BufferedOutputStream(FileOutputStream(outfile+'.cal',1)))
	    vfh = PrintStream(BufferedOutputStream(FileOutputStream(outfile+'.ver',1)))
    #
    i=0
    all = inputs + outputs
    iterator = MultiIterator(all)
    npattern = 1
    nskip = 0
    nprint_intvl = npatterns/10
    nprints = 0
    while not iterator.atEnd():
	if npattern%nprint_intvl == 0:
	    nprints = nprints + 1
	    print 'Done: %d%%'%(nprints*10)
	if nskip < skip:
	    nskip=nskip+1
	    iterator.advance()
	    continue
	if npattern > npatterns: break
	el = iterator.getElement()
	j=0
	#print el
	if npattern <= ncalibs:
	    fh = cfh
	    pattern_no = npattern
	    prev_pattern_no = prev_no_patterns[0]
	else:
	    fh = vfh
	    pattern_no = npattern - ncalibs
	    prev_pattern_no = prev_no_patterns[1]
	if fast_write:
	    fh.println()
	    fh.println('# Input pattern %d:'%(pattern_no+prev_pattern_no))
	else:
	    fh.write('\n# Input pattern %d:\n'%(pattern_no+prev_pattern_no))
	while j < ninputs:
	    if fast_write:
		fh.print('%10.6f'%el.getY(j))
	    else:
		fh.write('%10.6f'%el.getY(j))
	    j=j+1
	if fast_write:
	    fh.println()
	    fh.println('# Output pattern %d:'%(pattern_no+prev_pattern_no))
	else:
	    fh.write('\n# Output pattern %d:\n'%(pattern_no+prev_pattern_no))
	while j < ninputs+noutputs:
	    if fast_write:
		fh.print('%10.6f'%el.getY(j))
	    else:
		fh.write('%10.6f'%el.getY(j))
	    j=j+1
	if fast_write:
	    fh.println()
	else:
	    fh.write('\n')
	npattern = npattern+1
	iterator.advance()
    #
    cfh.close()
    vfh.close()
#
def prepare_simulate(net_file,module=None):
    '''
    prepare_simulate(net_file,module=None):
    prepares the java files needed from the given network file name
    and module name (optional)
    '''
    index = string.find(net_file,'.net')
    if index < 0: raise "Invalid name %s. Name should end with .net"%net_file
    net_name = net_file[:index]
    if module == None: module = net_name
    if not os.path.exists(net_file):
	raise "No network file %s exists!"%net_file
    if not os.path.exists('ANN'):
	os.mkdir('ANN')
    os.system('snns2c %s'%net_file)
    os.rename('%s.c ANN'%net_name)
    os.chdir('ANN')
    import snns2java
    snns2java.domain(['annutils','%s.c'%net_name,'%s'%module])
    os.system('javac *.java')
    os.chdir('..')
#
def simulate(inputs,ann_func,nouts=1):
    '''
    simulate(inputs,ann_func,nouts=1):

    this function simulates the given ann_func which is a string name of the
    function that exists in ANN package. The usual way to do this is to convert
    the SNNS generated "C" network to java using snns2java script. The generated
    java file is put in the ANN directory and compiled using "javac ann_func.java"
    command.

    inputs is the given inputs after being scaled and shifted for memory (Use
    buildinputs function for that)
    '''
    try:
	exec("from ANN import %s"%ann_func) in locals(), globals()
    except AttributeError, err:
	raise '''No function: %s defined
	Please make sure that function exists in the
	$CLASSPATH/ANN directory and is compiled'''%ann_func
    ann_obj = eval('%s()'%ann_func)
    mi = MultiIterator(inputs)
    ninps = len(inputs)
    input = jarray.zeros(ninps,'f')
    output = jarray.zeros(nouts,'f')
    ndata = len(inputs[0])
    #fh=open('%s_junk.data'%ann_func,'w')
    outarray = jarray.zeros(ndata,'f')
    input_no = 0
    nan_filter = NaNFilter()
    nprint_intvl = ndata/10
    nprints=0
    while input_no < ndata:
	if input_no%nprint_intvl == 0:
	    nprints=nprints+1
	    print 'Done: %d%%'%(nprints*10)
	el = mi.getElement()
	if nan_filter.isAcceptable(el):
	    i=0
	    #fh.write('%d\n'%input_no)
	    while i < ninps:
		input[i] = el.getY(i)
		#fh.write('%10.5f'%input[i])
		i=i+1
	    ann_obj.engine(input,output,0)
	    #fh.write('\n%10.5f\n'%output[0])
	    outarray[input_no] = output[0]
	else:
	    outarray[input_no] = Constants.MISSING_VALUE
	mi.advance()
	input_no=input_no+1
    stime = inputs[0].getStartTime().toString()
    #fh.close()
    ti = inputs[0].getTimeInterval().toString()
    rts = vutils.RegularTimeSeries('/ANN/%s/OUT///ANNUTILS-GEN/'%ann_func,stime,ti,outarray)
    return rts
#
def gmodel(ds,so,sb,beta,alpha,gprev=4000):
    """
    gmodel(ds,so,sb,beta,alpha,gprev=4000):

    This function takes a time series (probably NDO) and a set of parameters
    and returns a time series of the EC values.

    All the parameters are scaled and look at the source code listing for
    more information.

    For missing values the previous good flow value is used when calculating
    g. To change this strategy modify the source code.
    """
    #scaling the parameters
    lso = so*100
    lsb = sb*100
    lbeta = (1.0e+10)*beta
    lalpha = (1.0e-04)*alpha
    # no. of seconds in the time interval
    delt = ds.getTimeInterval()/timeinterval('1min')*60.0
    # get set ...
    dsi = ds.getIterator()
    ecvals = jarray.zeros(len(ds),'d') # create array to keep g values
    count=0
    # go... loop over all the flow values
    qval=0
    count=0
    while not dsi.atEnd():
	if filter.isAcceptable(dsi.getElement()):
	    qval = dsi.getElement().getY()
	else:
	    pass
	temp = (1+(qval/gprev-1)*math.exp(-qval*delt/lbeta))
	gprev = qval/temp
	ecvals[count] = (lso-lsb)*exp(-lalpha*gprev)+lsb
	count=count+1
    #
    name = ds.getName()
    parts = string.split(name,"/")
    old_b_part = parts[2]
    parts[2] = "EC (G)"
    parts[-2] = "FROM " + parts[2]
    name = string.join(parts,"/")
    ecrts = RegularTimeSeries(name,str(ds.getStartTime()), str(ds.getTimeInterval()), ecvals)
    return ecrts
#
def gcalc(ds,beta,delta_t,g_prev=0):
    """
    Function to calculate daily G values from net delta
    outflow conditions 
    
    G=Qavg/(1+(Qavg/Gprev-1)*exp(-Qavg*t/Beta))
    G,Qavg in cubic feet/sec
    t in seconds
    Beta in ft^3
    Beta for jerseypt = 550
    
    Gavg=Qavg + Beta/delta_t*ln((1+(Qavg/Gprev - 1)*exp(-Qavg*delta_t/Beta))/(Qavg/Gprev))
    
    """
    # no. of seconds in the time interval
    delta_t = ds.getTimeInterval()/timeinterval('1min')*60.0
    # get set ...
    dsi = ds.getIterator()
    gval = jarray.zeros(len(ds),'d') # create array to keep g values
    count=0
    # go... loop over all the flow values
    while not dsi.atEnd():
	q_avg = dsi.getElement().getY() # get current flow value.
	if g_prev == 0: g_prev=q_avg # if no g calcuated yet use q value...
	z1=beta/delta_t
	z2=q_avg/g_prev
	z3=-q_avg*delta_t/beta
	z4=z1*log((1+(z2-1)*exp(z3))/z2)
	g_avg=q_avg+z4
	gval[count] = g_avg
	g_prev=q_avg/(1+(z2-1)*exp(z3))
	dsi.advance(); count = count + 1
    #
    name = ds.getName()
    parts = string.split(name,"/")
    old_b_part = parts[2]
    parts[2] = "G CALC"
    parts[-2] = "FROM " + parts[2]
    name = string.join(parts,"/")
    grts = RegularTimeSeries(name,str(ds.getStartTime()), str(ds.getTimeInterval()), gval)
    return grts
def extractres(file='calibrate.res',stime='01jan1975 0000',time_intvl='1day'):
    """
    extractres(file='calibrate.res',stime='01jan1975 0000',time_intvl='1day'):

    Used to extract from result file a target and a simulated time series which
    starts at the start time and of the given time interval.

    The return value is a tuple of the target and simulated regular time series

    e.g.
    target,simulated = extractres('calibrate.res','01jan1975 0000','1day')
    """
    fh = open(file)
    nvals=0
    # get number of values... & loop till first pattern start
    while 1:
	line = fh.readline()
	if string.find(line,'#') >=0 :
	    fh.readline()
	    break
	if string.find(line,'No. of patterns') >= 0 :
	    line = string.strip(line)
	    nvals=int(string.split(line,':')[1])
    # make array of nvals
    if nvals == 0: raise "No data found --> No. of patterns = %d"%nvals
    print 'nvals = %d'%nvals
    target = jarray.zeros(nvals,'d')
    simulated = jarray.zeros(nvals,'d')
    # loop till end of file
    index=0
    last1 = ''
    last2 = ''
    display_intvl = 500
    while 1:
	line = fh.readline()
	if line == None or line == '': break
	if string.find(line,'#') >= 0:
	    if index%display_intvl == 0: print 'Done: %d of %d'%(index,nvals)
	    target[index]=float(last2)
	    simulated[index]=float(last1)
	    index=index+1
	else:
	    last2=last1
	    last1=line
    fh.close()
    rts_target = vutils.RegularTimeSeries('target',stime,time_intvl,target)
    rts_simulated = vutils.RegularTimeSeries('simulated',stime,time_intvl,simulated)
    return rts_target, rts_simulated
#
#
def _test1():
    g=vutils.opendss('/delta2/ann/hydrologies/sim809anndv.dss')
    refs = vutils.findpath(g,'//ndo/flow-ndo///')
    tw = vutils.timewindow('01jan1974 0000 - 01jan1992 0000')
    inps = []
    for i in range(len(refs)):
	inps.append(vutils.interpolate(DataReference.create(refs[i],tw).getData(),'1day'))
    print 'Got data for ',tw
    scaling = 8.99649e-07
    shift = 0.233677
    crush(inps[0],scaling,shift)
    print 'Crushed data'
    inputs = buildinput(inps[0],8,10,7)
    print 'Built inputs'
    outputs = inps[:]
    print 'Dumping patterns'
    dump_patterns(inputs,outputs,'junk',0.75)
#
def _test2():
    append=0
    for fpart in ['dxc-op','dxc-cl']:
	g1 = vutils.opendss('anninputs.dss')
	g2 = vutils.opendss('annoutputs.dss')
	g1.filterBy(fpart)
	refs = g1[:]
	tw = vutils.timewindow('01oct1975 0000 - 01sep1991 0000')
        #tw = vutils.timewindow('01oct1975 0000 - 01oct1976 0000')
	inps = []
	for i in range(len(refs)):
	    inps.append(vutils.interpolate(DataReference.create(refs[i],tw).getData(),'1day'))
	inputs = []
	for i in range(len(inps)):
	    print 'Building inputs for ',inps[i]
	    inputs=inputs+buildinput(inps[i],7,10,7) # weekly averages
	print 'Built inputs'
	outputs = []
	ccc_ref = vutils.findpath(g2,'//ccc/ec///%s/'%fpart)[0]
	outputs.append(vutils.interpolate(DataReference.create(ccc_ref,tw).getData(),'1day'))
	print 'Built outputs'
	print 'Dumping patterns'
	if append:
	    dump_patterns(inputs,outputs,'junk',0.75,365,1)
	else:
	    dump_patterns(inputs,outputs,'junk',0.75,365,append)
	    append = 1
#
def _test3():
    from ANN import fnet_cccec
    fpart = 'dxc-op'
    g1 = vutils.opendss('anninputs.dss')
    g2 = vutils.opendss('annoutputs.dss')
    g1.filterBy(fpart)
    g2.filterBy(fpart)
    refs = g1[:]
    tw = vutils.timewindow('01oct1975 0000 - 01sep1991 0000')
    #tw = vutils.timewindow('01oct1975 0000 - 01oct1976 0000')
    inps = []
    for i in range(len(refs)):
	inps.append(vutils.interpolate(DataReference.create(refs[i],tw).getData(),'1day'))
    inputs = []
    for i in range(len(inps)):
	print 'Building inputs for ',inps[i]
	inputs=inputs+buildinput(inps[i],7,10,7) # weekly averages
    print 'Built inputs'
    outputs = []
    ccc_ref = vutils.findpath(g2,'//ccc/ec///%s/'%fpart)[0]
    outputs.append(vutils.interpolate(DataReference.create(ccc_ref,tw).getData(),'1day'))
    mi = MultiIterator(inputs)
    import jarray
    ninps = len(inputs)
    input = jarray.zeros(ninps,'f')
    output = jarray.zeros(1,'f')
    ann = fnet_cccec()
    ndata = len(inputs[0])
    for input_no in range(365):
	mi.advance()
    outdata = jarray.zeros(ndata,'f')
    while input_no < ndata:
	el = mi.getElement()
	i=0
	while i < ninps:
	    input[i] = el.getY(i)
	    i=i+1
	ann.engine(input,output,0)
	outdata[input_no] = output[0]
	mi.advance()
	input_no=input_no+1
    #
    stime = inputs[0].getStartTime()
    ti = inputs[0].getTimeInterval()
    rtsout = vutils.RegularTimeSeries('/ann/ccc_out/ec///annutils/',str(stime),\
				      str(ti),outdata)
    vutils.plot(rtsout,outputs[0])
    rtsout = (rtsout-0.140516)/0.000396563
    vutils.writedss('annout.dss','/ann/ccc_out/ec///annutils/',rtsout)
#
def _test4():
    from ANN import fnet_cccec
    sac = vutils.RegularTimeSeries('inp1','31jan1990 2400', '1mon', [10000.0, 11000.0, 12000.0, 15000.0])
    sac = sac*5.40394e-06+0.178546
    sjr = vutils.RegularTimeSeries('inp1','31jan1990 2400', '1mon', [1000.0, 1100.0, 1200.0, 1500.0])
    sjr = sjr*1.34396e-05+0.199247
    exp = vutils.RegularTimeSeries('inp1','31jan1990 2400', '1mon', [5000.0, 6000.0, 7000.0, 8000.0])
    exp = exp*-4.86697e-05+0.178537
    dxc = vutils.RegularTimeSeries('inp1','31jan1990 2400', '1mon', [0.0, 0.0, 0.0, 0.0])
    dxc = (1.-dxc/31)*0.6+0.2
    inps = [dxc,exp,sac,sjr]
    inps = map(lambda x: vutils.interpolate(x,'1day'), inps)
    inputs = []
    for i in range(len(inps)):
	print 'Building inputs for ',inps[i]
	inputs=inputs+buildinput(inps[i],7,10,7) # weekly averages
    print 'Built inputs'
    #outputs = []
    #ccc_ref = vutils.findpath(g2,'//ccc/ec///%s/'%fpart)[0]
    #outputs.append(vutils.interpolate(DataReference.create(ccc_ref,tw).getData(),'1day'))
    mi = MultiIterator(inputs)
    import jarray
    ninps = len(inputs)
    input = jarray.zeros(ninps,'f')
    output = jarray.zeros(1,'f')
    ann = fnet_cccec()
    ndata = len(inputs[0])
    for input_no in range(31+28+31+1):
	mi.advance()
    outdata = jarray.zeros(ndata,'f')
    fh = open('junk.out','w',15000)
    while input_no < ndata:
	el = mi.getElement()
	i=0
	while i < ninps:
	    input[i] = el.getY(i)
	    i=i+1
	ann.engine(input,output,0)
	fh.write('Input #: %d\n'%input_no)
	i=0
	while i < ninps:
	    fh.write('%13.6f'%input[i])
	    if i%5 == 4: fh.write('\n')
	    i = i+1
	fh.write('\nOutput #: %d\n'%input_no)
	fh.write('%13.6f\n'%output[0])
	outdata[input_no] = output[0]
	mi.advance()
	input_no=input_no+1
    fh.close()
    #
def testnet():
    import ANN
    from ANN import fnet_orrsl
    net = fnet_orrsl()
    inputs = [0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.25091,0.28,0.28,0.75273,0.8]
    inputs = inputs + [-0.38572,-0.38572,-0.38572,-0.38572,-0.32603,-0.32603,-0.32603,-0.32603,-0.32603,-0.32603,-0.51225,-0.73572,-0.73572,-0.55445,-0.45087,-0.45087,-0.14874,-0.11853]
    inputs = inputs + [0.24562,0.24562,0.24562,0.24562,0.24724,0.24724,0.24724,0.24724,0.24724,0.24724,0.27394,0.30599,0.30599,0.29444,0.28784,0.28784,0.27508,0.27381]
    inputs = inputs + [0.22902,0.22902,0.22902,0.22902,0.2215,0.2215,0.2215,0.2215,0.2215,0.2215,0.22178,0.22212,0.22212,0.2312,0.23638,0.23638,0.29549,0.3014]
    inputs = jarray.array(inputs,'f')
    #print inputs
    outputs = jarray.zeros(1,'f')
    net.engine(inputs,outputs,1)
    # expected output was 0.30921 got 0.30920425, slightly off?
    print outputs[0]
